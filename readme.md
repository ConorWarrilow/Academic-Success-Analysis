# $${\color{#00D8DB}\text{Machine Learning For Early Detection of} \space \color{#00D8DB}\text{Students at} \space \color{#00D8DB}\text{Risk}}$$

The transition to higher education can be challenging for many students, and many factors can influence academic performance. As a result, some students may struggle to keep up with the demands of their coursework, leading to increased dropout rates and underperformance. The use of machine learning for Early detection of students on the path to dropping out can help catch problems early and allow universities to implement intervention strategies on a student-to-student basis.




# $${\color{#00D8DB}\text{Goals}}$$

1. To explore and assess the feature sthat may indicate whether a student is on the path to dropping out, gradiating, or remaining enrolled by the end of the normal duration of their course.
2. To construct a machine learning model aimed towards the early detection of students displaying the signs associated with dropping their course.
3. Analyze the pitfalls of a purely machine learning based approach and determine what improvements can be made to increase our rate of early detection

   



# $${\color{#00D8DB}\text{Table of Contents}}$$


The data set provided contains a total of 36 features relating to academic performance age gender attendant style Marshall status course type parent qualifications or occupations and various social economic metrics.

A full list of [features and their definitons can be found here.](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success)

The situation is a multiclass classification, with 3 classes to predict.

**Target value Labels:**

0 - Dropout
1 - Graduate
2 - Enrolled


# $${\color{#00D8DB}\text{1. Exploratory Data Analysis}}$$

## $${\color{#00A5A8}\text{1.1 The Basics}}$$

### Initial EDA
- No missing/null values
- 8 binary/boolean columns
- 7 float columns
- 21 integer columns
- 0 categorical columns

### Data Types
Several Integer columns appear appropriate for one-hot-encoding.

###Target Class Imbalance





## $${\color{#00A5A8}\text{1.2 Correlations}}$$

## $${\color{#00A5A8}\text{1.3 Kde and Cumulative Kde plots and Analysis}}$$



# $${\color{#00D8DB}\text{2. Feature Transformations}}$$

## $${\color{#00A5A8}\text{2.1 Transformation Types}}$$

## $${\color{#00A5A8}\text{2.2 Handling Categorical Data}}$$

## $${\color{#00A5A8}\text{2.3 Normalization and Standardization}}$$




# $${\color{#00D8DB}\text{3. Feature Importance Analysis}}$$

## $${\color{#00A5A8}\text{3.1 Impurity-Based Feature Importance}}$$

## $${\color{#00A5A8}\text{3.2 Permutation-Based Feature Importance}}$$

## $${\color{#00A5A8}\text{3.3 Altermative Methods of Feature Importance}}$$



# $${\color{#00D8DB}\text{4. Feature Engineering}}$$



# $${\color{#00D8DB}\text{5. Machine Learning}}$$

## $${\color{#00A5A8}\text{5.1 Building a Pipeline}}$$

## $${\color{#00A5A8}\text{5.2 Building a Pipeline}}$$

## $${\color{#00A5A8}\text{5.3 Selecting the Right Model}}$$

## $${\color{#00A5A8}\text{5.4 Hyperparameter Tuning}}$$

## $${\color{#00A5A8}\text{5.5 Stacked Ensembles}}$$



# $${\color{#00D8DB}\text{6. Results}}$$



# $${\color{#00D8DB}\text{7. Further Analysis}}$$










